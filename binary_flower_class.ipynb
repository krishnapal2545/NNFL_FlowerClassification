{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 150, 150, 3) (1800,)\n"
     ]
    }
   ],
   "source": [
    "#Change the DIRECTORY link according to your file location\n",
    "DIRECTORY = r'C:\\Users\\Krishna\\Desktop\\K.J.TYBTech\\NNFL\\IA2\\flowers'\n",
    "Categories = ['rose', 'sunflower']\n",
    "\n",
    "IMAGE_SIZE = 150\n",
    "\n",
    "data = []\n",
    "\n",
    "for category in Categories:\n",
    "    folder = os.path.join(DIRECTORY, category)\n",
    "    label = Categories.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder,img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.resize(img_arr,(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        data.append([img_arr,label])\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "total_images = []\n",
    "total_labels = []\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for features, labels in data:\n",
    "    train_images.append(features)\n",
    "    train_labels.append(labels)\n",
    "    total_images.append(features)\n",
    "    total_labels.append(labels)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "train_images = train_images/255\n",
    "\n",
    "print(train_images.shape , train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 150, 150, 3) (600,)\n"
     ]
    }
   ],
   "source": [
    "TEST_DIRECTORY = r'C:\\Users\\Krishna\\Desktop\\K.J.TYBTech\\NNFL\\IA2\\test-flowers'\n",
    "Categories = ['rose', 'sunflower']\n",
    "\n",
    "IMAGE_SIZE = 150\n",
    "test_data = []\n",
    "\n",
    "for category in Categories:\n",
    "    folder = os.path.join(TEST_DIRECTORY, category)\n",
    "    label = Categories.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder,img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.resize(img_arr,(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        # plt.imshow(img_arr)\n",
    "        # break\n",
    "        test_data.append([img_arr,label])\n",
    "\n",
    "random.shuffle(test_data)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for features, labels in test_data:\n",
    "    test_images.append(features)\n",
    "    test_labels.append(labels)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images = test_images/255\n",
    "\n",
    "print(test_images.shape , test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data using train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(total_images, total_labels, test_size=0.15, random_state=42)\n",
    "trainX = np.array(trainX)\n",
    "trainX = trainX/255\n",
    "trainY = np.array(trainY)\n",
    "testX = np.array(testX)\n",
    "testX = testX/255\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Tensorboard file for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "NAME = f'flower-prediction-{int(time.time())}'\n",
    "tens_board = TensorBoard(log_dir=f'logs\\\\{NAME}\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model on CNN Architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation= 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,input_shape = train_images.shape[1:], activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images,train_labels, epochs= 10, validation_split= 0.1, batch_size= 32, callbacks=[tens_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "print(\"Evaluate on test data\")\n",
    "predict_result = model.evaluate(test_images, test_labels, batch_size=32)\n",
    "print(\"test loss, test acc:\", predict_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load VGG16 Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_images[0].shape)\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "Vggmodel = Sequential()\n",
    "\n",
    "Vggmodel.add(base_model)\n",
    "Vggmodel.add(Flatten())\n",
    "Vggmodel.add(Dense(50, input_shape = train_images.shape[1:], activation='relu'))\n",
    "Vggmodel.add(Dense(20, activation='relu'))\n",
    "Vggmodel.add(Dense(5, activation='softmax'))\n",
    "\n",
    "Vggmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "Vggmodel.fit(train_images, train_labels, epochs=10, validation_split=0.1, batch_size=32, callbacks=[tens_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "print(\"Evaluate on test data\")\n",
    "Vgg_predict_result = Vggmodel.evaluate(test_images, test_labels, batch_size=32)\n",
    "print(\"test loss, test acc:\", Vgg_predict_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 110s 2s/step - loss: 0.7171 - accuracy: 0.5636 - val_loss: 0.5852 - val_accuracy: 0.7444\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 97s 2s/step - loss: 0.6179 - accuracy: 0.6519 - val_loss: 0.6072 - val_accuracy: 0.6111\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 93s 2s/step - loss: 0.5994 - accuracy: 0.6735 - val_loss: 0.6265 - val_accuracy: 0.6056\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 97s 2s/step - loss: 0.5484 - accuracy: 0.7290 - val_loss: 0.4781 - val_accuracy: 0.8167\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 95s 2s/step - loss: 0.4913 - accuracy: 0.7593 - val_loss: 0.5424 - val_accuracy: 0.6889\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 95s 2s/step - loss: 0.4671 - accuracy: 0.7759 - val_loss: 0.4555 - val_accuracy: 0.8556\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 99s 2s/step - loss: 0.4439 - accuracy: 0.7975 - val_loss: 0.4393 - val_accuracy: 0.8667\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 96s 2s/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.5641 - val_accuracy: 0.7278\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 96s 2s/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.4361 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 96s 2s/step - loss: 0.3926 - accuracy: 0.8309 - val_loss: 0.7701 - val_accuracy: 0.6167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b565d9d30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Load ResNet50 Model\n",
    "from keras.applications.resnet import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "ResNetmodel = Sequential()\n",
    "ResNetmodel.add(base_model)  \n",
    "ResNetmodel.add(Flatten())\n",
    "ResNetmodel.add(Dense(50, input_shape = train_images.shape[1:], activation='relu'))\n",
    "ResNetmodel.add(Dense(20, activation='relu'))\n",
    "ResNetmodel.add(Dense(5, activation='softmax'))\n",
    "\n",
    "ResNetmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "ResNetmodel.fit(train_images, train_labels, epochs=10, validation_split=0.1, batch_size=32, callbacks=[tens_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "19/19 [==============================] - 32s 2s/step - loss: 0.8267 - accuracy: 0.5700\n",
      "test loss, test acc: [0.8266504406929016, 0.5699999928474426]\n"
     ]
    }
   ],
   "source": [
    "#prediction on test data\n",
    "print(\"Evaluate on test data\")\n",
    "ResNet_predict_result = ResNetmodel.evaluate(test_images, test_labels, batch_size=32)\n",
    "print(\"test loss, test acc:\", ResNet_predict_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
